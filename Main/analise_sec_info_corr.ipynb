#%% md
### Bibliotecas
#%%
import pandas as pd
import numpy as np
import seaborn as sns
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix
import matplotlib.pyplot as plt
from sklearn.model_selection import StratifiedKFold
from sklearn.metrics import roc_curve, auc, precision_recall_curve, average_precision_score
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout
from sklearn.preprocessing import StandardScaler
from imblearn.over_sampling import SMOTE
from flaml import AutoML
#%% md
### Carregando Dados
#%%
df_benign = pd.read_csv(r'D:\Projetos\UFABC\UFABC_SI\Dados\Benign Traffic.csv')
#%%
df_mqtt_ddos_publish = pd.read_csv(r'D:\Projetos\UFABC\UFABC_SI\Dados\MQTT DDoS Publish Flood.csv')
#%%
df_mqtt_dos_connect = pd.read_csv(r'D:\Projetos\UFABC\UFABC_SI\Dados\MQTT DoS Connect Flood.csv')
#%%
df_mqtt_dos_publish = pd.read_csv(r'D:\Projetos\UFABC\UFABC_SI\Dados\MQTT DoS Publish Flood.csv')
#%%
df_mqtt_malformed = pd.read_csv(r'D:\Projetos\UFABC\UFABC_SI\Dados\MQTT Malformed.csv')
#%% md
### Criando classiicação

#%%
df_benign['Target'] = 'Benign'
df_mqtt_ddos_publish['Target'] = 'DDoS Publish Flood'
df_mqtt_dos_connect['Target'] = 'DoS Connect Flood'
df_mqtt_dos_publish['Target'] = 'DoS Publish Flood'
df_mqtt_malformed['Target'] = 'Malformed'
#%% md
#### Junção DFS

#%%
df_fail = pd.concat([
    df_benign,
    df_mqtt_ddos_publish,
    df_mqtt_dos_connect,
    df_mqtt_dos_publish,
    df_mqtt_malformed
], ignore_index=True)
#%% md
### Conversão para datetime
#%%
df_fail['Timestamp_data'] = df_fail['Timestamp'].astype(str).str.split(expand=True)[0]
df_fail['Timestamp_hora'] = df_fail['Timestamp'].astype(str).str.split(expand=True)[1]
#%% md
### Exploração dos dados
#%%
df_fail.info()
#%%
df_fail.describe()
#%%
df_fail['Attack Name'].unique()
#%%
df_fail.corr(numeric_only=True)
#%%
sns.heatmap(df_fail.corr(numeric_only=True))
#%% md
### Engenharia de Features
#%% md
### 1. Features de Janela Deslizante (Rolling Window)
#%%
# Vamos criar features que representam a média, desvio padrão, mínimo e máximo dos sensores em diferentes janelas de tempo (5, 15 e 30 períodos).

# Garante que os dados estão ordenados por equipamento e tempo
df_feat = df_fail.sort_values(by=['Flow ID', 'Timestamp']).copy()
#%%
# Célula para inserir após o sort_values
# Lista de colunas numéricas para aplicar as features
features_to_engineer = [
    'Flow Duration',
    'Total Fwd Packet',
    'Total Bwd packets',
    'Total Length of Fwd Packet',
    'Total Length of Bwd Packet',
    'Fwd Packet Length Max',
    'Fwd Packet Length Min',
    'Fwd Packet Length Mean',
    'Fwd Packet Length Std',
    'Bwd Packet Length Max',
    'Bwd Packet Length Min',
    'Bwd Packet Length Mean',
    'Bwd Packet Length Std',
    'Flow IAT Mean',
    'Flow IAT Std',
    'Flow IAT Max',
    'Flow IAT Min',
    'Fwd IAT Total',
    'Fwd IAT Mean',
    'Fwd IAT Std',
    'Fwd IAT Max',
    'Fwd IAT Min'
]
#%%
# Célula para inserir após o sort_values
# Lista de colunas numéricas para aplicar as features
#Foi comentado pois usava todas as colunas numericas

#numeric_cols = df_feat.select_dtypes(include=np.number).columns.tolist()
#%%
# Janelas de tempo a serem usadas
window_sizes = [5, 10, 20]
#%%
for feature in features_to_engineer:
    for window in window_sizes:
        # Agrupa por ID e aplica a janela deslizante
        rolling_mean = df_feat.groupby('Flow ID')[feature].rolling(window=window, min_periods=1).mean().reset_index(
            drop=True)
        rolling_std = df_feat.groupby('Flow ID')[feature].rolling(window=window, min_periods=1).std().reset_index(drop=True)
        rolling_max = df_feat.groupby('Flow ID')[feature].rolling(window=window, min_periods=1).max().reset_index(drop=True)

        df_feat[f'{feature}_mean_{window}'] = rolling_mean
        df_feat[f'{feature}_std_{window}'] = rolling_std
        df_feat[f'{feature}_max_{window}'] = rolling_max

print("Features de janela deslizante criadas.")
#%% md
### 2. Features de Atraso (Lag Features)
#%%
# Criaremos colunas com os valores dos sensores de 1, 2 e 3 períodos atrás.

lags = [1, 2, 3]

for feature in features_to_engineer:
    for lag in lags:
        # Agrupa por ID e aplica o shift
        df_feat[f'{feature}_lag_{lag}'] = df_feat.groupby('Flow ID')[feature].shift(lag)

print("Features de atraso criadas.")
#%% md
### 3. Limpeza Final do DataFrame de Features
#%%
# A criação de janelas e lags gera valores NaN no início de cada série temporal (por equipamento).
# Vamos remover essas linhas para garantir que o modelo só treine com dados completos.

print(f"Tamanho do DataFrame antes da limpeza de NaN: {df_feat.shape}")

# Remove todas as linhas que contenham qualquer valor NaN gerado
df_feat.dropna(inplace=True)

print(f"Tamanho do DataFrame após a limpeza: {df_feat.shape}")

# Visualizando o resultado final com as novas features
df_feat.head()
#%%
# A criação de janelas e lags gera valores NaN no início de cada série temporal (por equipamento).
# Vamos remover essas linhas para garantir que o modelo só treine com dados completos.

print(f"Tamanho do DataFrame antes da limpeza de NaN: {df_feat.shape}")

# Remove todas as linhas que contenham qualquer valor NaN gerado
df_feat.dropna(inplace=True)

print(f"Tamanho do DataFrame após a limpeza: {df_feat.shape}")

# Visualizando o resultado final com as novas features
df_feat.head()
#%% md
### 4. Features Avançadas
#%% md
#### 4.1 Features de Tendência (Slope)

#%%
# Vamos calcular a inclinação (slope) dos dados dos sensores dentro de uma janela para capturar a tendência de subida ou descida.

# Função para calcular a inclinação (slope) de uma janela
def get_slope(array):
    # polyfit é mais rápido para isso
    y = np.array(array)
    x = np.arange(len(y))
    # O primeiro elemento de polyfit é a inclinação
    slope = np.polyfit(x, y, 1)[0]
    return slope

window_trend = 15  # Janela para cálculo da tendência

for feature in features_to_engineer:
    # Agrupa por ID e aplica a função de slope na janela
    trend = df_feat.groupby('Flow ID')[feature].rolling(window=window_trend, min_periods=window_trend).apply(get_slope,
                                                                                                        raw=True).reset_index(
        drop=True)
    df_feat[f'{feature}_trend_{window_trend}'] = trend

print("Features de tendência criadas.")
#%% md
#### 4.2 Features Cíclicas de Tempo
#%%
# Primeiro, converte a coluna 'Timestamp' para o formato datetime
df_feat['Timestamp'] = pd.to_datetime(df_feat['Timestamp'])
#%%
# Transformar a hora do dia em features de seno e cosseno para que o modelo entenda a natureza cíclica do tempo.

df_feat['hora'] = df_feat['Timestamp'].dt.hour
df_feat['hora_sin'] = np.sin(2 * np.pi * df_feat['hora'] / 24.0)
df_feat['hora_cos'] = np.cos(2 * np.pi * df_feat['hora'] / 24.0)
df_feat.drop('hora', axis=1, inplace=True)

print("Features cíclicas de tempo criadas.")
#%% md
#### 4.3 Limpeza Final Pós-Features Avançadas
#%%
print(f"Tamanho antes da limpeza final: {df_feat.shape}")
df_feat.dropna(inplace=True)
print(f"Tamanho após a limpeza final: {df_feat.shape}")
df_feat.head()
#%% md
### 5: Modelagem (Machine Learning)
#%% md
#### 5.1. Preparação dos Dados para o Modelo
#%%
# Selecionando as features (X) e o alvo (y)
# Vamos remover colunas de identificação, tempo e as features originais dos sensores

columns_to_remove_manually = ['Timestamp', 'Attack Name', 'Flow ID', 'Timestamp_data', 'Timestamp_hora', 'Target',
                              'Src IP', 'Dst IP', 'Src Port', 'Protocol']

features_to_drop = columns_to_remove_manually + features_to_engineer

X = df_feat.drop(columns=features_to_drop)
y = df_feat['Target']

# Divisão em treino e teste (80/20) de forma temporal
split_index = int(len(X) * 0.8)

X_train, X_test = X[:split_index], X[split_index:]
y_train, y_test = y[:split_index], y[split_index:]

print(f"Tamanho do conjunto de treino: {X_train.shape}")
print(f"Tamanho do conjunto de teste: {X_test.shape}")
#%% md
#### 5.2. Treinamento do Modelo de Baseline (Random Forest)
#%%
# Usamos class_weight='balanced' para lidar com o desbalanceamento das classes (poucas falhas)
rf_model = RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced', n_jobs=-1)

print("Iniciando o treinamento do modelo Random Forest...")
rf_model.fit(X_train, y_train)
print("Treinamento concluído.")
#%% md
#### 5.3. Avaliação do Modelo
#%%
y_pred = rf_model.predict(X_test)

print("--- Relatório de Classificação no Conjunto de Teste ---")
print(classification_report(y_test, y_pred))

# Pega os nomes das classes (rótulos) em ordem alfabética para o gráfico
class_labels = sorted(y_test.unique())

cm = confusion_matrix(y_test, y_pred)
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', 
            xticklabels=class_labels, yticklabels=class_labels)
plt.title('Matriz de Confusão')
plt.ylabel('Verdadeiro')
plt.xlabel('Previsto')
plt.show()
#%% md
### 6: Avaliação e Interpretabilidade
#%% md
#### 6.1. Importância das Features (Feature Importance)

#%%
# Agora que temos um modelo treinado, podemos extrair a importância de cada feature.
# Isso nos diz quais variáveis o modelo considerou mais relevantes para fazer as previsões.

importances = rf_model.feature_importances_
feature_names = X_train.columns

# Criando um DataFrame para melhor visualização
feature_importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': importances})
feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)
#%%
plt.figure(figsize=(12, 8))
sns.barplot(x='Importance', y='Feature', data=feature_importance_df.head(20))
plt.title('Top 20 Features Mais Importantes para o Modelo Random Forest')
plt.xlabel('Importância')
plt.ylabel('Feature')
plt.show()
#%% md
### 7: Balanceamento de Dados e Otimização com AutoML
#%% md
#### 7.1. Balanceamento do Conjunto de Treino com SMOTE
#%%
print("Contagem de classes antes do SMOTE:")
print(y_train.value_counts())

# Aplicando SMOTE apenas nos dados de treino
smote = SMOTE(random_state=42)
X_train_balanced, y_train_balanced = smote.fit_resample(X_train, y_train)

print("\nContagem de classes após o SMOTE:")
print(y_train_balanced.value_counts())
#%% md
#### 7.2. Busca do Melhor Modelo com AutoML (FLAML)
#%%
# Instanciando o AutoML
automl = AutoML()

# Configurações para a busca do modelo
# Usaremos 'f1' como métrica, que é mais indicada para dados desbalanceados.
automl_settings = {
    "time_budget": 120,  # Tempo em segundos para a busca (ex: 2 minutos)
    "metric": 'f1',
    "task": 'classification',
    "log_file_name": 'flaml_soft_hard_failure.log',
    "eval_method": "holdout"
}

print("\nIniciando a busca do melhor modelo com AutoML...")
# O fit será feito com os dados de treino balanceados
# A validação (X_val, y_val) usa o conjunto de teste original, que não foi modificado
automl.fit(X_train=X_train_balanced, y_train=y_train_balanced,
           X_val=X_test, y_val=y_test,
           **automl_settings)

print("Busca concluída.")
#%% md
#### 7.3. Avaliação do Melhor Modelo Encontrado pelo AutoML
#%%
print("--- Resultados do AutoML ---")
print(f"Melhor modelo encontrado: {automl.model.estimator}")
print(f"Melhor F1-score na validação: {1 - automl.best_loss:.4f}")

# Fazendo previsões no conjunto de teste
y_pred_automl = automl.predict(X_test)

print("\n--- Relatório de Classificação do Melhor Modelo no Conjunto de Teste ---")
print(classification_report(y_test, y_pred_automl))

print("\n--- Matriz de Confusão do Melhor Modelo ---")
cm_automl = confusion_matrix(y_test, y_pred_automl)
sns.heatmap(cm_automl, annot=True, fmt='d', cmap='Greens', xticklabels=class_labels, yticklabels=class_labels)

plt.title('Matriz de Confusão - Melhor Modelo (AutoML)')
plt.ylabel('Verdadeiro')
plt.xlabel('Previsto')
plt.show()
#%% md
### 8: Abordagem com Deep Learning (LSTM)
#%%
# É crucial normalizar os dados para modelos de Deep Learning.
# O scaler é treinado APENAS com os dados de treino para evitar data leakage.
scaler = StandardScaler()

# Usamos os dados de treino balanceados para treinar o scaler
X_train_scaled = scaler.fit_transform(X_train_balanced)

# Aplicamos a mesma transformação nos dados de teste
X_test_scaled = scaler.transform(X_test)

print("Dados normalizados com sucesso.")
#%% md
#### 8.1. Remodelagem dos Dados para o Formato da LSTM
#%%
# A LSTM espera uma entrada 3D: (amostras, timesteps, features)
# Como nossas features já representam um estado no tempo, usaremos 1 timestep.
X_train_reshaped = X_train_scaled.reshape((X_train_scaled.shape[0], 1, X_train_scaled.shape[1]))
X_test_reshaped = X_test_scaled.reshape((X_test_scaled.shape[0], 1, X_test_scaled.shape[1]))

print(f"Novo shape do treino: {X_train_reshaped.shape}")
print(f"Novo shape do teste: {X_test_reshaped.shape}")
#%% md
#### 8.2. Construção e Treinamento do Modelo LSTM
#%%
model_lstm = Sequential()
model_lstm.add(LSTM(50, input_shape=(X_train_reshaped.shape[1], X_train_reshaped.shape[2])))
model_lstm.add(Dropout(0.2))
model_lstm.add(Dense(1, activation='sigmoid')) # Saída binária (Falha ou Normal)

model_lstm.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

model_lstm.summary()

# Treinando o modelo com os dados balanceados e normalizados
history = model_lstm.fit(X_train_reshaped, y_train_balanced, epochs=10, batch_size=64, validation_data=(X_test_reshaped, y_test), verbose=1)

#%% md
#### 8.3. Avaliação do Modelo LSTM
#%%
# Fazendo previsões (o resultado será um array de probabilidades por classe)
y_pred_proba_lstm = model_lstm.predict(X_test_reshaped)
y_pred_lstm = np.argmax(y_pred_proba_lstm, axis=1) # Pega a classe com a maior probabilidade

print("\n--- Relatório de Classificação do Modelo LSTM no Conjunto de Teste ---")
print(classification_report(y_test, y_pred_lstm, target_names=label_encoder.classes_))

print("\n--- Matriz de Confusão do Modelo LSTM ---")
cm_lstm = confusion_matrix(y_test, y_pred_lstm)
sns.heatmap(cm_lstm, annot=True, fmt='d', cmap='Oranges', xticklabels=class_labels, yticklabels=class_labels)
plt.title('Matriz de Confusão - Modelo LSTM')
plt.ylabel('Verdadeiro')
plt.xlabel('Previsto')
plt.show()
#%% md
### 9: Validação Robusta e Análise de Curvas
#%% md
Para garantir que o desempenho do nosso melhor modelo não foi resultado de uma divisão de dados favorável, vamos reavaliá-lo usando uma metodologia mais robusta: a Validação Cruzada Estratificada. Além disso, plotaremos as curvas ROC e Precision-Recall para uma análise mais profunda.
#%% md
#### 9.1. Re-treinamento com Validação Cruzada Estratificada
#%%
# Usaremos os parâmetros do melhor modelo encontrado pelo AutoML (ou um modelo similar robusto)
# Nota: O AutoML encontrou um RF com n_estimators=8. Para robustez, usaremos um valor mais padrão como 100.
best_model = RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced', n_jobs=-1)
#%%
# Usaremos o dataset completo (antes do split temporal) para a validação cruzada
# Isso nos dará uma medida de quão bem o modelo generaliza em diferentes subconjuntos de dados.
X_full = df_feat.drop(columns=features_to_drop)
y_full = df_feat['Target']

# Configurando a validação cruzada com 5 folds
cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)

f1_scores = []
recall_scores = []

print("Iniciando a Validação Cruzada Estratificada...")
for fold, (train_idx, val_idx) in enumerate(cv.split(X_full, y_full)):
    X_train_cv, X_val_cv = X_full.iloc[train_idx], X_full.iloc[val_idx]
    y_train_cv, y_val_cv = y_full.iloc[train_idx], y_full.iloc[val_idx]

    # Balanceamento SMOTE dentro de cada fold de treino
    smote_cv = SMOTE(random_state=42)
    X_train_cv_balanced, y_train_cv_balanced = smote_cv.fit_resample(X_train_cv, y_train_cv)

    best_model.fit(X_train_cv_balanced, y_train_cv_balanced)
    y_pred_cv = best_model.predict(X_val_cv)

    report = classification_report(y_val_cv, y_pred_cv, output_dict=True)
    f1_scores.append(report['1']['f1-score'])
    recall_scores.append(report['1']['recall'])
    print(f"Fold {fold+1}: F1-Score (Falha) = {f1_scores[-1]:.4f}, Recall (Falha) = {recall_scores[-1]:.4f}")
#%%
print(f"\n--- Média dos Resultados da Validação Cruzada ---")
print(f"F1-Score Médio (Falha): {np.mean(f1_scores):.4f} ± {np.std(f1_scores):.4f}")
print(f"Recall Médio (Falha): {np.mean(recall_scores):.4f} ± {np.std(recall_scores):.4f}")
#%% md
#### 9.2. Análise de Curvas (ROC e Precision-Recall)
#%%
# Para plotar as curvas, usamos as previsões de probabilidade do modelo no conjunto de teste original
y_proba = rf_model.predict_proba(X_test)[:, 1] # Probabilidade da classe 'Falha'

# Curva ROC
fpr, tpr, _ = roc_curve(y_test, y_proba)
roc_auc = auc(fpr, tpr)

# Curva Precision-Recall
precision, recall, _ = precision_recall_curve(y_test, y_proba)
pr_auc = average_precision_score(y_test, y_proba)

fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))

# Plot da Curva ROC
ax1.plot(fpr, tpr, color='darkorange', lw=2, label=f'Curva ROC (AUC = {roc_auc:.2f})')
ax1.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
ax1.set_xlim([0.0, 1.0])
ax1.set_ylim([0.0, 1.05])
ax1.set_xlabel('Taxa de Falsos Positivos')
ax1.set_ylabel('Taxa de Verdadeiros Positivos')
ax1.set_title('Curva ROC')
ax1.legend(loc="lower right")

# Plot da Curva Precision-Recall
ax2.plot(recall, precision, color='blue', lw=2, label=f'Curva P-R (AP = {pr_auc:.2f})')
ax2.set_xlabel('Recall')
ax2.set_ylabel('Precision')
ax2.set_title('Curva Precision-Recall')
ax2.legend(loc="lower left")

plt.tight_layout()
plt.show()
#%% md
### 10: Análise Comparativa, Conclusões e Trabalhos Futuros
#%% md
#### 10.1. Tabela Comparativa de Desempenho no Conjunto de Teste
#%% md
#### 10.2. Análise Consolidada dos Resultados
#%% md
#### 10.3. Conclusão e Trabalhos Futuros