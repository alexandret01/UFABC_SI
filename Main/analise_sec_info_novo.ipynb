{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "7c0589a0f1dd909"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Bibliotecas",
   "id": "3c827535bb5c9b6d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from imblearn.over_sampling import SMOTE"
   ],
   "id": "185c2c492fd90bbd"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Carregando Dados",
   "id": "b3a15043f9242a6d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Carregamento de dados dinâmico\n",
    "import os\n",
    "\n",
    "data_path = r'D:\\Projetos\\UFABC\\UFABC_SI\\Dados'\n",
    "files = {\n",
    "    'Benign Traffic.csv': 'Benign',\n",
    "    'MQTT DDoS Publish Flood.csv': 'DDoS Publish Flood',\n",
    "    'MQTT DoS Connect Flood.csv': 'DoS Connect Flood',\n",
    "    'MQTT DoS Publish Flood.csv': 'DoS Publish Flood',\n",
    "    'MQTT Malformed.csv': 'Malformed'\n",
    "}\n",
    "\n",
    "dfs = []\n",
    "for filename, target_name in files.items():\n",
    "    try:\n",
    "        df = pd.read_csv(os.path.join(data_path, filename))\n",
    "        df['Target'] = target_name\n",
    "        dfs.append(df)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Aviso: Arquivo não encontrado e será ignorado: {filename}\")\n",
    "\n",
    "df_fail = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "print(\"Dados carregados e concatenados com sucesso.\")\n",
    "display(df_fail['Target'].value_counts())\n"
   ],
   "id": "c0e5741ca609bf0b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Pré-processamento e Exploração",
   "id": "2782f234786cbea5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Conversão de Timestamp e limpeza de nomes de colunas\n",
    "df_fail['Timestamp'] = pd.to_datetime(df_fail['Timestamp'], errors='coerce')\n",
    "df_fail.columns = df_fail.columns.str.strip() # Remove espaços em branco dos nomes das colunas\n",
    "\n",
    "# Remove linhas onde o Timestamp não pôde ser convertido\n",
    "df_fail.dropna(subset=['Timestamp'], inplace=True)\n",
    "\n",
    "df_fail.info()"
   ],
   "id": "d5d52adacb60f532"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "df_fail.describe()",
   "id": "6182f2c61827c41f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Verificando a distribuição do alvo\n",
    "sns.countplot(y=df_fail['Target'])\n",
    "plt.title('Distribuição das Classes de Tráfego')\n",
    "plt.show()"
   ],
   "id": "a818d5ee949180d9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Engenharia de Features\n",
    "# Para análises de série temporal, é crucial que os dados estejam ordenados."
   ],
   "id": "8ef374bab6bcc1c2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "df_feat = df_fail.sort_values(by=['Flow ID', 'Timestamp']).copy()\n",
    "\n",
    "# Lista de colunas numéricas para engenharia de features\n",
    "features_to_engineer = [\n",
    "    'Flow Duration', 'Total Fwd Packet', 'Total Bwd packets',\n",
    "    'Total Length of Fwd Packet', 'Total Length of Bwd Packet',\n",
    "    'Fwd Packet Length Max', 'Fwd Packet Length Min', 'Fwd Packet Length Mean', 'Fwd Packet Length Std',\n",
    "    'Bwd Packet Length Max', 'Bwd Packet Length Min', 'Bwd Packet Length Mean', 'Bwd Packet Length Std',\n",
    "    'Flow IAT Mean', 'Flow IAT Std', 'Flow IAT Max', 'Flow IAT Min',\n",
    "    'Fwd IAT Total', 'Fwd IAT Mean', 'Fwd IAT Std', 'Fwd IAT Max', 'Fwd IAT Min'\n",
    "]\n",
    "\n",
    "# Garantir que todas as colunas existem antes de prosseguir\n",
    "features_to_engineer = [col for col in features_to_engineer if col in df_feat.columns]\n",
    "\n",
    "print(\"Iniciando engenharia de features...\")\n",
    "\n",
    "# 1. Features de Janela Deslizante (Rolling Window)\n",
    "window_sizes = [5, 10, 20]\n",
    "for feature in features_to_engineer:\n",
    "    for window in window_sizes:\n",
    "        df_feat[f'{feature}_mean_{window}'] = df_feat.groupby('Flow ID')[feature].rolling(window=window, min_periods=1).mean().reset_index(drop=True)\n",
    "        df_feat[f'{feature}_std_{window}'] = df_feat.groupby('Flow ID')[feature].rolling(window=window, min_periods=1).std().reset_index(drop=True)\n",
    "\n",
    "# 2. Features de Atraso (Lag Features)\n",
    "lags = [1, 2, 3]\n",
    "for feature in features_to_engineer:\n",
    "    for lag in lags:\n",
    "        df_feat[f'{feature}_lag_{lag}'] = df_feat.groupby('Flow ID')[feature].shift(lag)\n",
    "\n",
    "# 3. Features Cíclicas de Tempo\n",
    "df_feat['hora_sin'] = np.sin(2 * np.pi * df_feat['Timestamp'].dt.hour / 24.0)\n",
    "df_feat['hora_cos'] = np.cos(2 * np.pi * df_feat['Timestamp'].dt.hour / 24.0)\n",
    "\n",
    "print(\"Engenharia de features concluída.\")\n",
    "\n",
    "# Limpeza de NaNs gerados pela engenharia de features\n",
    "print(f\"Tamanho antes da limpeza de NaN: {df_feat.shape}\")\n",
    "df_feat.dropna(inplace=True)\n",
    "df_feat.reset_index(drop=True, inplace=True)\n",
    "print(f\"Tamanho após a limpeza de NaN: {df_feat.shape}\")\n"
   ],
   "id": "39bc0a825c41e785"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 5: Modelagem (Machine Learning)",
   "id": "e2f0cc7928efa351"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 5.1. Preparação dos Dados para o Modelo",
   "id": "193bef6e96677ed0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Colunas a serem removidas antes da modelagem\n",
    "# Inclui identificadores, timestamps, colunas de texto e as features originais que foram transformadas\n",
    "\n",
    "# Identificar colunas de texto/objeto que não foram tratadas\n",
    "object_cols = df_feat.select_dtypes(include='object').columns.tolist()\n",
    "# Manter a coluna 'Target' por enquanto\n",
    "if 'Target' in object_cols:\n",
    "    object_cols.remove('Target')\n",
    "\n",
    "features_to_drop = ['Timestamp', 'Attack Name', 'Flow ID'] + object_cols + features_to_engineer\n",
    "\n",
    "# Garantir que não estamos tentando dropar colunas que não existem\n",
    "features_to_drop = list(set([col for col in features_to_drop if col in df_feat.columns]))\n",
    "\n",
    "X = df_feat.drop(columns=features_to_drop + ['Target'])\n",
    "y = df_feat['Target']\n",
    "\n",
    "# Codificar os rótulos (y) de texto para números\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "num_classes = len(label_encoder.classes_)\n",
    "\n",
    "print(f\"Classes encontradas e codificadas: {dict(zip(label_encoder.classes_, range(num_classes)))}\")\n",
    "\n",
    "# Divisão em treino e teste (80/20) de forma temporal\n",
    "split_index = int(len(X) * 0.8)\n",
    "\n",
    "X_train, X_test = X.iloc[:split_index], X.iloc[split_index:]\n",
    "y_train, y_test = y_encoded[:split_index], y_encoded[split_index:]\n",
    "y_train_labels, y_test_labels = y.iloc[:split_index], y.iloc[split_index:] # Guardar labels de texto para relatórios\n",
    "\n",
    "print(f\"Tamanho do conjunto de treino: {X_train.shape}\")\n",
    "print(f\"Tamanho do conjunto de teste: {X_test.shape}\")\n"
   ],
   "id": "5f3f815bfe30c301"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 5.2. Treinamento do Modelo de Baseline (Random Forest)",
   "id": "1d055084cabff867"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced', n_jobs=-1)\n",
    "\n",
    "print(\"Iniciando o treinamento do modelo Random Forest...\")\n",
    "rf_model.fit(X_train, y_train)\n",
    "print(\"Treinamento concluído.\")\n"
   ],
   "id": "c16b0864573329e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 5.3. Avaliação do Modelo",
   "id": "38c27e30c778235b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "print(\"--- Relatório de Classificação no Conjunto de Teste ---\")\n",
    "print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=label_encoder.classes_, yticklabels=label_encoder.classes_)\n",
    "plt.title('Matriz de Confusão - Random Forest')\n",
    "plt.ylabel('Verdadeiro')\n",
    "plt.xlabel('Previsto')\n",
    "plt.show()\n"
   ],
   "id": "7eb9a4b9a2ff0ae3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 8: Abordagem com Deep Learning (LSTM)",
   "id": "5fb80481f1228618"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 8.1. Balanceamento e Normalização",
   "id": "c3bf7d5375754f92"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "print(\"Contagem de classes no treino antes do SMOTE:\")\n",
    "print(y_train_labels.value_counts())\n",
    "\n",
    "# Aplicando SMOTE apenas nos dados de treino\n",
    "smote = SMOTE(random_state=42, k_neighbors=1) # k_neighbors=1 pois uma classe tem apenas 2 amostras\n",
    "X_train_balanced, y_train_balanced = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "print(\"\\nContagem de classes no treino após o SMOTE:\")\n",
    "print(pd.Series(y_train_balanced).value_counts())\n",
    "\n",
    "# Normalização dos dados\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_balanced)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"Dados balanceados e normalizados com sucesso.\")\n"
   ],
   "id": "164e7c31b331b59f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 8.2. Remodelagem e Construção do Modelo LSTM",
   "id": "8196e8cff136e956"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# A LSTM espera uma entrada 3D: (amostras, timesteps, features)\n",
    "X_train_reshaped = X_train_scaled.reshape((X_train_scaled.shape[0], 1, X_train_scaled.shape[1]))\n",
    "X_test_reshaped = X_test_scaled.reshape((X_test_scaled.shape[0], 1, X_test_scaled.shape[1]))\n",
    "\n",
    "# Construção do Modelo LSTM para classificação multiclasse\n",
    "model_lstm = Sequential()\n",
    "model_lstm.add(LSTM(50, input_shape=(X_train_reshaped.shape[1], X_train_reshaped.shape[2])))\n",
    "model_lstm.add(Dropout(0.2))\n",
    "model_lstm.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model_lstm.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model_lstm.summary()\n"
   ],
   "id": "e2266b9c35454cc7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 8.3. Treinamento e Avaliação do Modelo LSTM",
   "id": "55dab382367a15db"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "print(\"Iniciando o treinamento do modelo LSTM...\")\n",
    "history = model_lstm.fit(X_train_reshaped, y_train_balanced, \n",
    "                         epochs=10, \n",
    "                         batch_size=64, \n",
    "                         validation_data=(X_test_reshaped, y_test), \n",
    "                         verbose=1)\n",
    "\n",
    "# Avaliação\n",
    "y_pred_proba_lstm = model_lstm.predict(X_test_reshaped)\n",
    "y_pred_lstm = np.argmax(y_pred_proba_lstm, axis=1)\n",
    "\n",
    "print(\"\\n--- Relatório de Classificação do Modelo LSTM ---\")\n",
    "print(classification_report(y_test, y_pred_lstm, target_names=label_encoder.classes_))\n",
    "\n",
    "cm_lstm = confusion_matrix(y_test, y_pred_lstm)\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(cm_lstm, annot=True, fmt='d', cmap='Oranges', \n",
    "            xticklabels=label_encoder.classes_, yticklabels=label_encoder.classes_)\n",
    "plt.title('Matriz de Confusão - Modelo LSTM')\n",
    "plt.ylabel('Verdadeiro')\n",
    "plt.xlabel('Previsto')\n",
    "plt.show()\n"
   ],
   "id": "1296cb8bbeecdfc3"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
