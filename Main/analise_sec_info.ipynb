#%% md
### Bibliotecas
#%%
import pandas as pd
import numpy as np
import seaborn as sns
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix
import matplotlib.pyplot as plt
from sklearn.model_selection import StratifiedKFold
from sklearn.metrics import roc_curve, auc, precision_recall_curve, average_precision_score
# Importações necessárias para a correção do LSTM
from sklearn.preprocessing import StandardScaler, LabelEncoder
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout
from tensorflow.keras.utils import to_categorical # Para One-Hot Encoding
from imblearn.over_sampling import SMOTE
from flaml import AutoML
#%% md
### Carregando Dados
#%%
df_benign = pd.read_csv(r'D:\Projetos\UFABC\UFABC_SI\Dados\Benign Traffic.csv')
#%%
df_mqtt_ddos_publish = pd.read_csv(r'D:\Projetos\UFABC\UFABC_SI\Dados\MQTT DDoS Publish Flood.csv')
#%%
df_mqtt_dos_connect = pd.read_csv(r'D:\Projetos\UFABC\UFABC_SI\Dados\MQTT DoS Connect Flood.csv')
#%%
df_mqtt_dos_publish = pd.read_csv(r'D:\Projetos\UFABC\UFABC_SI\Dados\MQTT DoS Publish Flood.csv')
#%%
df_mqtt_malformed = pd.read_csv(r'D:\Projetos\UFABC\UFABC_SI\Dados\MQTT Malformed.csv')
#%% md
### Criando classiicação

#%%
df_benign['Target'] = 'Benign'
df_mqtt_ddos_publish['Target'] = 'DDoS Publish Flood'
df_mqtt_dos_connect['Target'] = 'DoS Connect Flood'
df_mqtt_dos_publish['Target'] = 'DoS Publish Flood'
df_mqtt_malformed['Target'] = 'Malformed'
#%% md
#### Junção DFS

#%%
df_fail = pd.concat([
    df_benign,
    df_mqtt_ddos_publish,
    df_mqtt_dos_connect,
    df_mqtt_dos_publish,
    df_mqtt_malformed
], ignore_index=True)
#%% md
### Conversão para datetime
#%%
df_fail['Timestamp_data'] = df_fail['Timestamp'].astype(str).str.split(expand=True)[0]
df_fail['Timestamp_hora'] = df_fail['Timestamp'].astype(str).str.split(expand=True)[1]
#%% md
### Exploração dos dados
#%%
df_fail.info()
#%%
df_fail.describe()
#%%
df_fail['Attack Name'].unique()
#%%
df_fail.corr(numeric_only=True)
#%%
sns.heatmap(df_fail.corr(numeric_only=True))
#%% md
### Engenharia de Features
#%% md
### 1. Features de Janela Deslizante (Rolling Window)
#%%
# Vamos criar features que representam a média, desvio padrão, mínimo e máximo dos sensores em diferentes janelas de tempo (5, 15 e 30 períodos).

# Garante que os dados estão ordenados por equipamento e tempo
df_feat = df_fail.sort_values(by=['Flow ID', 'Timestamp']).copy()
#%%
# Célula para inserir após o sort_values
# Lista de colunas numéricas para aplicar as features
features_to_engineer = [
    'Flow Duration',
    'Total Fwd Packet',
    'Total Bwd packets',
    'Total Length of Fwd Packet',
    'Total Length of Bwd Packet',
    'Fwd Packet Length Max',
    'Fwd Packet Length Min',
    'Fwd Packet Length Mean',
    'Fwd Packet Length Std',
    'Bwd Packet Length Max',
    'Bwd Packet Length Min',
    'Bwd Packet Length Mean',
    'Bwd Packet Length Std',
    'Flow IAT Mean',
    'Flow IAT Std',
    'Flow IAT Max',
    'Flow IAT Min',
    'Fwd IAT Total',
    'Fwd IAT Mean',
    'Fwd IAT Std',
    'Fwd IAT Max',
    'Fwd IAT Min'
]
#%%
# Célula para inserir após o sort_values
# Lista de colunas numéricas para aplicar as features
#Foi comentado pois usava todas as colunas numericas

#numeric_cols = df_feat.select_dtypes(include=np.number).columns.tolist()
#%%
# Janelas de tempo a serem usadas
window_sizes = [5, 10, 20]
#%%
for feature in features_to_engineer:
    for window in window_sizes:
        # Agrupa por ID e aplica a janela deslizante
        rolling_mean = df_feat.groupby('Flow ID')[feature].rolling(window=window, min_periods=1).mean().reset_index(
            drop=True)
        rolling_std = df_feat.groupby('Flow ID')[feature].rolling(window=window, min_periods=1).std().reset_index(drop=True)
        rolling_max = df_feat.groupby('Flow ID')[feature].rolling(window=window, min_periods=1).max().reset_index(drop=True)

        df_feat[f'{feature}_mean_{window}'] = rolling_mean
        df_feat[f'{feature}_std_{window}'] = rolling_std
        df_feat[f'{feature}_max_{window}'] = rolling_max

print("Features de janela deslizante criadas.")
#%% md
### 2. Features de Atraso (Lag Features)
#%%
# Criaremos colunas com os valores dos sensores de 1, 2 e 3 períodos atrás.

lags = [1, 2, 3]

for feature in features_to_engineer:
    for lag in lags:
        # Agrupa por ID e aplica o shift
        df_feat[f'{feature}_lag_{lag}'] = df_feat.groupby('Flow ID')[feature].shift(lag)

print("Features de atraso criadas.")
#%% md
### 3. Limpeza Final do DataFrame de Features
#%%
# A criação de janelas e lags gera valores NaN no início de cada série temporal (por equipamento).
# Vamos remover essas linhas para garantir que o modelo só treine com dados completos.

print(f"Tamanho do DataFrame antes da limpeza de NaN: {df_feat.shape}")

# Remove todas as linhas que contenham qualquer valor NaN gerado
df_feat.dropna(inplace=True)

print(f"Tamanho do DataFrame após a limpeza: {df_feat.shape}")

# Visualizando o resultado final com as novas features
df_feat.head()
#%%
# A criação de janelas e lags gera valores NaN no início de cada série temporal (por equipamento).
# Vamos remover essas linhas para garantir que o modelo só treine com dados completos.

print(f"Tamanho do DataFrame antes da limpeza de NaN: {df_feat.shape}")

# Remove todas as linhas que contenham qualquer valor NaN gerado
df_feat.dropna(inplace=True)

print(f"Tamanho do DataFrame após a limpeza: {df_feat.shape}")

# Visualizando o resultado final com as novas features
df_feat.head()
#%% md
### 4. Features Avançadas
#%% md
#### 4.1 Features de Tendência (Slope)

#%%
# Vamos calcular a inclinação (slope) dos dados dos sensores dentro de uma janela para capturar a tendência de subida ou descida.

# Função para calcular a inclinação (slope) de uma janela
def get_slope(array):
    # polyfit é mais rápido para isso
    y = np.array(array)
    x = np.arange(len(y))
    # O primeiro elemento de polyfit é a inclinação
    slope = np.polyfit(x, y, 1)[0]
    return slope

window_trend = 15  # Janela para cálculo da tendência

for feature in features_to_engineer:
    # Agrupa por ID e aplica a função de slope na janela
    trend = df_feat.groupby('Flow ID')[feature].rolling(window=window_trend, min_periods=window_trend).apply(get_slope,
                                                                                                                   raw=True).reset_index(
        drop=True)
    df_feat[f'{feature}_trend_{window_trend}'] = trend

print("Features de tendência criadas.")
#%% md
#### 4.2 Features Cíclicas de Tempo
#%%
# Primeiro, converte a coluna 'Timestamp' para o formato datetime
df_feat['Timestamp'] = pd.to_datetime(df_feat['Timestamp'])
#%%
# Transformar a hora do dia em features de seno e cosseno para que o modelo entenda a natureza cíclica do tempo.

df_feat['hora'] = df_feat['Timestamp'].dt.hour
df_feat['hora_sin'] = np.sin(2 * np.pi * df_feat['hora'] / 24.0)
df_feat['hora_cos'] = np.cos(2 * np.pi * df_feat['hora'] / 24.0)
df_feat.drop('hora', axis=1, inplace=True)

print("Features cíclicas de tempo criadas.")
#%% md
#### 4.3 Limpeza Final Pós-Features Avançadas
#%%
print(f"Tamanho antes da limpeza final: {df_feat.shape}")
df_feat.dropna(inplace=True)
print(f"Tamanho após a limpeza final: {df_feat.shape}")
df_feat.head()
#%% md
### 5: Modelagem (Machine Learning)
#%% md
#### 5.1. Preparação dos Dados para o Modelo
#%%
# Selecionando as features (X) e o alvo (y)
# Vamos remover colunas de identificação, tempo e as features originais dos sensores

columns_to_remove_manually = ['Timestamp', 'Attack Name', 'Flow ID', 'Timestamp_data', 'Timestamp_hora', 'Target',
                              'Src IP', 'Dst IP', 'Src Port', 'Protocol']

features_to_drop = columns_to_remove_manually + features_to_engineer

X = df_feat.drop(columns=features_to_drop)
y = df_feat['Target']

# Divisão em treino e teste (80/20) de forma temporal
split_index = int(len(X) * 0.8)

X_train, X_test = X[:split_index], X[split_index:]
y_train, y_test = y[:split_index], y[split_index:]

print(f"Tamanho do conjunto de treino: {X_train.shape}")
print(f"Tamanho do conjunto de teste: {X_test.shape}")
#%% md
#### 5.2. Treinamento do Modelo de Baseline (Random Forest)
#%%
# Usamos class_weight='balanced' para lidar com o desbalanceamento das classes (poucas falhas)
rf_model = RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced', n_jobs=-1)

print("Iniciando o treinamento do modelo Random Forest...")
rf_model.fit(X_train, y_train)
print("Treinamento concluído.")
#%% md
#### 5.3. Avaliação do Modelo
#%%
y_pred = rf_model.predict(X_test)

print("--- Relatório de Classificação no Conjunto de Teste ---")
print(classification_report(y_test, y_pred))

# Pega os nomes das classes (rótulos) em ordem alfabética para o gráfico
class_labels = sorted(y_test.unique())

cm = confusion_matrix(y_test, y_pred)
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', 
            xticklabels=class_labels, yticklabels=class_labels)
plt.title('Matriz de Confusão')
plt.ylabel('Verdadeiro')
plt.xlabel('Previsto')
plt.show()
#%% md
### 6: Avaliação e Interpretabilidade
#%% md
#### 6.1. Importância das Features (Feature Importance)

#%%
# Agora que temos um modelo treinado, podemos extrair a importância de cada feature.
# Isso nos diz quais variáveis o modelo considerou mais relevantes para fazer as previsões.

importances = rf_model.feature_importances_
feature_names = X_train.columns

# Criando um DataFrame para melhor visualização
feature_importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': importances})
feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)
#%%
plt.figure(figsize=(12, 8))
sns.barplot(x='Importance', y='Feature', data=feature_importance_df.head(20))
plt.title('Top 20 Features Mais Importantes para o Modelo Random Forest')
plt.xlabel('Importância')
plt.ylabel('Feature')
plt.show()
#%% md
### 7: Balanceamento de Dados e Otimização com AutoML
#%% md
#### 7.1. Balanceamento do Conjunto de Treino com SMOTE
#%%
print("Contagem de classes antes do SMOTE:")
print(y_train.value_counts())

# Aplicando SMOTE apenas nos dados de treino
smote = SMOTE(random_state=42)
X_train_balanced, y_train_balanced = smote.fit_resample(X_train, y_train)

print("\nContagem de classes após o SMOTE:")
print(y_train_balanced.value_counts())
#%% md
#### 7.2. Busca do Melhor Modelo com AutoML (FLAML)
#%%
# Instanciando o AutoML
automl = AutoML()

# Configurações para a busca do modelo
# Usaremos 'f1_macro' (ou 'f1' para binário) como métrica. Para multiclasse, 'f1_macro' ou 'f1_weighted' são melhores.
# FLAML usa 'f1' por padrão para binário, e o mais apropriado para multiclasse é 'f1_macro' (macro-average F1).
automl_settings = {
    "time_budget": 120,  # Tempo em segundos para a busca (ex: 2 minutos)
    "metric": 'f1_macro', # Ajustado para multiclasse
    "task": 'classification',
    "log_file_name": 'flaml_multi_class_failure.log',
    "eval_method": "holdout"
}

print("\nIniciando a busca do melhor modelo com AutoML...")
# O fit será feito com os dados de treino balanceados
# A validação (X_val, y_val) usa o conjunto de teste original, que não foi modificado
automl.fit(X_train=X_train_balanced, y_train=y_train_balanced,
           X_val=X_test, y_val=y_test,
           **automl_settings)

print("Busca concluída.")
#%% md
#### 7.3. Avaliação do Melhor Modelo Encontrado pelo AutoML
#%%
print("--- Resultados do AutoML ---")
print(f"Melhor modelo encontrado: {automl.model.estimator}")
print(f"Melhor F1-score (Macro) na validação: {1 - automl.best_loss:.4f}")

# Fazendo previsões no conjunto de teste
y_pred_automl = automl.predict(X_test)

print("\n--- Relatório de Classificação do Melhor Modelo no Conjunto de Teste ---")
print(classification_report(y_test, y_pred_automl))

print("\n--- Matriz de Confusão do Melhor Modelo ---")
cm_automl = confusion_matrix(y_test, y_pred_automl)
sns.heatmap(cm_automl, annot=True, fmt='d', cmap='Greens', xticklabels=class_labels, yticklabels=class_labels)

plt.title('Matriz de Confusão - Melhor Modelo (AutoML)')
plt.ylabel('Verdadeiro')
plt.xlabel('Previsto')
plt.show()
#%% md
#### 7.4. Codificação de Rótulos para LSTM
# **Célula de correção: Cria o label_encoder e faz a codificação para o modelo LSTM/Keras**
#%%
# 1. Codificação numérica dos rótulos (Label Encoding)
label_encoder = LabelEncoder()
y_train_encoded = label_encoder.fit_transform(y_train_balanced) # O label encoder é treinado com os dados de treino balanceados
y_test_encoded = label_encoder.transform(y_test)

# 2. One-Hot Encoding (OHE) para Keras (multiclasse)
y_train_ohe = to_categorical(y_train_encoded)
y_test_ohe = to_categorical(y_test_encoded)
num_classes = len(label_encoder.classes_)

print(f"Número de classes: {num_classes}")
print(f"Shape de y_train para LSTM (OHE): {y_train_ohe.shape}")
print(f"Classes codificadas: {label_encoder.classes_}")
#%% md
### 8: Abordagem com Deep Learning (LSTM)
#%%
# É crucial normalizar os dados para modelos de Deep Learning.
# O scaler é treinado APENAS com os dados de treino para evitar data leakage.
scaler = StandardScaler()

# Usamos os dados de treino balanceados para treinar o scaler
X_train_scaled = scaler.fit_transform(X_train_balanced)

# Aplicamos a mesma transformação nos dados de teste
X_test_scaled = scaler.transform(X_test)

print("Dados normalizados com sucesso.")
#%% md
#### 8.1. Remodelagem dos Dados para o Formato da LSTM
#%%
# A LSTM espera uma entrada 3D: (amostras, timesteps, features)
# Como nossas features já representam um estado no tempo, usaremos 1 timestep.
X_train_reshaped = X_train_scaled.reshape((X_train_scaled.shape[0], 1, X_train_scaled.shape[1]))
X_test_reshaped = X_test_scaled.reshape((X_test_scaled.shape[0], 1, X_test_scaled.shape[1]))

print(f"Novo shape do treino: {X_train_reshaped.shape}")
print(f"Novo shape do teste: {X_test_reshaped.shape}")
#%% md
#### 8.2. Construção e Treinamento do Modelo LSTM
# **Célula corrigida: Modelo agora configurado para classificação multiclasse (5 classes)**
#%%
model_lstm = Sequential()
model_lstm.add(LSTM(50, input_shape=(X_train_reshaped.shape[1], X_train_reshaped.shape[2])))
model_lstm.add(Dropout(0.2))
model_lstm.add(Dense(num_classes, activation='softmax')) # Saída multiclasse corrigida

model_lstm.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy']) # Loss para OHE multiclasse

model_lstm.summary()

# Treinando o modelo com os dados balanceados e normalizados (usando y_ohe)
history = model_lstm.fit(X_train_reshaped, y_train_ohe, epochs=10, batch_size=64, validation_data=(X_test_reshaped, y_test_ohe), verbose=1)

#%% md
#### 8.3. Avaliação do Modelo LSTM
# **Célula corrigida: Agora usa o label_encoder e os dados codificados corretamente.**
#%%
# Fazendo previsões (o resultado será um array de probabilidades por classe)
y_pred_proba_lstm = model_lstm.predict(X_test_reshaped)
# Converte as probabilidades OHE para a classe de maior probabilidade (índice numérico)
y_pred_lstm_encoded = np.argmax(y_pred_proba_lstm, axis=1) 
# Converte os índices numéricos de volta para os rótulos de string
y_pred_lstm_labels = label_encoder.inverse_transform(y_pred_lstm_encoded) 

print("\n--- Relatório de Classificação do Modelo LSTM no Conjunto de Teste ---")
# Compara os rótulos originais de y_test com os rótulos previstos pelo LSTM
print(classification_report(y_test, y_pred_lstm_labels, target_names=label_encoder.classes_)) 

print("\n--- Matriz de Confusão do Modelo LSTM ---")
cm_lstm = confusion_matrix(y_test, y_pred_lstm_labels)
sns.heatmap(cm_lstm, annot=True, fmt='d', cmap='Oranges', xticklabels=class_labels, yticklabels=class_labels)
plt.title('Matriz de Confusão - Modelo LSTM')
plt.ylabel('Verdadeiro')
plt.xlabel('Previsto')
plt.show()
#%% md
### 9: Validação Robusta e Análise de Curvas
#%% md
Para garantir que o desempenho do nosso melhor modelo não foi resultado de uma divisão de dados favorável, vamos reavaliá-lo usando uma metodologia mais robusta: a Validação Cruzada Estratificada. Além disso, plotaremos as curvas ROC e Precision-Recall para uma análise mais profunda.
#%% md
#### 9.1. Re-treinamento com Validação Cruzada Estratificada
# **Nota:** A análise de curva ROC e métricas para cada classe na validação cruzada para **multiclasse** é complexa. A métrica 'f1' do relatório é o F1-score ponderado (weighted average) ou macro average. Vamos usar 'macro avg' como indicador.
#%%
# Usaremos os parâmetros do melhor modelo encontrado pelo AutoML (ou um modelo similar robusto)
# Nota: O AutoML encontrou um RF com n_estimators=8. Para robustez, usaremos um valor mais padrão como 100.
best_model = RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced', n_jobs=-1)
#%%
# Usaremos o dataset completo (antes do split temporal) para a validação cruzada
# Isso nos dará uma medida de quão bem o modelo generaliza em diferentes subconjuntos de dados.
X_full = df_feat.drop(columns=features_to_drop)
y_full = df_feat['Target']

# Configurando a validação cruzada com 5 folds
cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)

f1_macro_scores = []
recall_macro_scores = []

print("Iniciando a Validação Cruzada Estratificada...")
for fold, (train_idx, val_idx) in enumerate(cv.split(X_full, y_full)):
    X_train_cv, X_val_cv = X_full.iloc[train_idx], X_full.iloc[val_idx]
    y_train_cv, y_val_cv = y_full.iloc[train_idx], y_full.iloc[val_idx]

    # Balanceamento SMOTE dentro de cada fold de treino
    smote_cv = SMOTE(random_state=42)
    X_train_cv_balanced, y_train_cv_balanced = smote_cv.fit_resample(X_train_cv, y_train_cv)

    best_model.fit(X_train_cv_balanced, y_train_cv_balanced)
    y_pred_cv = best_model.predict(X_val_cv)

    report = classification_report(y_val_cv, y_pred_cv, output_dict=True)
    f1_macro_scores.append(report['macro avg']['f1-score'])
    recall_macro_scores.append(report['macro avg']['recall'])
    print(f"Fold {fold+1}: F1-Score (Macro Avg) = {f1_macro_scores[-1]:.4f}, Recall (Macro Avg) = {recall_macro_scores[-1]:.4f}")
#%%
print(f"\n--- Média dos Resultados da Validação Cruzada ---")
print(f"F1-Score Médio (Macro Avg): {np.mean(f1_macro_scores):.4f} ± {np.std(f1_macro_scores):.4f}")
print(f"Recall Médio (Macro Avg): {np.mean(recall_macro_scores):.4f} ± {np.std(recall_macro_scores):.4f}")
#%% md
#### 9.2. Análise de Curvas (ROC e Precision-Recall)
# **Nota:** Para problemas multiclasse, a análise é feita "One-vs-Rest". Usaremos o `label_encoder` criado anteriormente.
#%%
# 1. Preparar os dados para as curvas (necessário codificar y_test para OHE)
y_test_encoded = label_encoder.transform(y_test)
y_test_ohe_full = to_categorical(y_test_encoded, num_classes=num_classes)
class_labels_list = list(label_encoder.classes_)

# 2. Obter as probabilidades para todas as classes (Random Forest)
y_proba_rf = rf_model.predict_proba(X_test) 

# Arrays para armazenar métricas
fpr = dict()
tpr = dict()
roc_auc = dict()
precision = dict()
recall = dict()
pr_auc = dict()

# Calcular métricas para cada classe (One-vs-Rest)
for i in range(num_classes):
    # ROC
    fpr[i], tpr[i], _ = roc_curve(y_test_ohe_full[:, i], y_proba_rf[:, i])
    roc_auc[i] = auc(fpr[i], tpr[i])
    
    # Precision-Recall
    precision[i], recall[i], _ = precision_recall_curve(y_test_ohe_full[:, i], y_proba_rf[:, i])
    pr_auc[i] = average_precision_score(y_test_ohe_full[:, i], y_proba_rf[:, i])

# Plotar as curvas
fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 7))

# Plot da Curva ROC (OvR)
for i in range(num_classes):
    ax1.plot(fpr[i], tpr[i], lw=2, 
             label=f'Curva ROC - {class_labels_list[i]} (AUC = {roc_auc[i]:.2f})')
ax1.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
ax1.set_xlim([0.0, 1.0])
ax1.set_ylim([0.0, 1.05])
ax1.set_xlabel('Taxa de Falsos Positivos')
ax1.set_ylabel('Taxa de Verdadeiros Positivos')
ax1.set_title('Curva ROC - One-vs-Rest (Random Forest)')
ax1.legend(loc="lower right")

# Plot da Curva Precision-Recall (OvR)
for i in range(num_classes):
    ax2.plot(recall[i], precision[i], lw=2, 
             label=f'Curva P-R - {class_labels_list[i]} (AP = {pr_auc[i]:.2f})')

ax2.set_xlabel('Recall')
ax2.set_ylabel('Precision')
ax2.set_title('Curva Precision-Recall - One-vs-Rest (Random Forest)')
ax2.legend(loc="lower left")

plt.tight_layout()
plt.show()
#%% md
### 10: Análise Comparativa, Conclusões e Trabalhos Futuros
#%% md
#### 10.1. Tabela Comparativa de Desempenho no Conjunto de Teste
#%% md
#### 10.2. Análise Consolidada dos Resultados
#%% md
#### 10.3. Conclusão e Trabalhos Futuros
